{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook for Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short example to perform linear regression in python using sklearn using salaries data and dummy variables.\n",
    "\n",
    "We show how to transform them using panda or sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import math\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's upload the dataset\n",
    "# data = pd.read_csv('../Dataset/Salaries.csv')   you should put the file inthe correct folder.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop useless columns\n",
    "data = data.drop('Unnamed: 0', axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploit categorical data\n",
    "print(pd.unique(data['rank']))\n",
    "print(pd.unique(data['discipline']))\n",
    "print(pd.unique(data['sex']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seprate X and y\n",
    "X = data.drop('salary', axis = 1)\n",
    "y = data[['salary']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have three variables that can be transformed in dummies.\n",
    "\n",
    "Let's start with the easy case: Discipline has only two variables and we use the LabelEncoder() form the preprocessing package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's transofrm and use only one simple variable that can take only two values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use pd.get_dummies or LabelEncoder\n",
    "# 1. using get_dummies\n",
    "dummies_pd = pd.get_dummies(data['discipline'])\n",
    "dummies_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use pd.get_dummies or LabelEncoder\n",
    "# 2. using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "dummies_encoder = le.fit_transform(data[['discipline']])\n",
    "dummies_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that dummies_encoder is the same as the column B.\n",
    "\n",
    "We can just use the colum B of the matrix that we obtain using pd.get_dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show what X.assign() does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using get dummies\n",
    "X_get_dummies = X.assign(Discipline_dummy = dummies_pd[['B']])\n",
    "X_get_dummies = X_get_dummies.drop('discipline', axis = 1)\n",
    "\n",
    "# or we can use and then we build a data frame using it\n",
    "X_get_dummies2 = np.hstack((X.drop('discipline', axis = 1), dummies_pd[['B']]))\n",
    "X_get_dummies2_df = pd.DataFrame(X_get_dummies2, columns=['rank','yrs.since.phd', 'yrs.service',\n",
    "                                                          'sex', 'discipline_dummy'])\n",
    "X_get_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_get_dummies2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using labelencoder\n",
    "X_le = X.assign(Discipline_dummy = dummies_encoder)\n",
    "X_le = X_le.drop('discipline', axis = 1)\n",
    "\n",
    "# or we can use and then we build a data frame using it\n",
    "X_le2 = np.hstack((X.drop('discipline', axis = 1), dummies_pd[['B']]))\n",
    "X_le2_df = pd.DataFrame(X_get_dummies2, columns=['rank','yrs.since.phd', 'yrs.service','sex',\n",
    "                                                         'discipline_dummy'])\n",
    "X_le.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_le2_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this data transformation and manipulation let's fit the linea regresson model.\n",
    "\n",
    "- 1. Let's split the sample in trainig test and test set\n",
    "- 2. Fit the model\n",
    "- 3. Predict using the model \n",
    "- 4. Evaluate the performances\n",
    "\n",
    "I will use only X_get_dummies and X_le to show you we get the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First case: Let's use only the continous variables and the dummy we have created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using get dummies  (we can use alternatively X_le)  \n",
    "X_ex1 = X_get_dummies[['yrs.since.phd','yrs.service','Discipline_dummy']]\n",
    "X_train, X_test, y_train,y_test = train_test_split(X_ex1, y,\n",
    "                                                  test_size = 0.2,\n",
    "                                                  random_state = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. fit the model\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. predict the model\n",
    "y_pred = lm.predict(X_test)\n",
    "\n",
    "index_name = ['intercept', 'yrs.since.phd','yrs.service','Discipline_dummy']\n",
    "\n",
    "# coef \n",
    "coef = pd.DataFrame(np.append(lm.intercept_, lm.coef_), \n",
    "                    index_name, columns = ['coefficients'])\n",
    "\n",
    "# 4. evaluate the model\n",
    "print('MSE linear regression using only 3 variables: ', \n",
    "      mean_squared_error(y_test, y_pred))\n",
    "print('RMSE linear regression using only 3 variables: ', \n",
    "      math.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('R2 linear regression using only 3 variables: ', \n",
    "      r2_score(y_test, y_pred))\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using X_le (same results)\n",
    "# 1. split sample\n",
    "X_ex1 = X_le[['yrs.since.phd','yrs.service','Discipline_dummy']]\n",
    "X_train, X_test, y_train,y_test = train_test_split(X_ex1, y,\n",
    "                                                  test_size = 0.2,\n",
    "                                                  random_state = 10)\n",
    "\n",
    "# 2. fit the model\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "# 3. predict the model\n",
    "y_pred = lm.predict(X_test)\n",
    "index_name = ['intercept', 'yrs.since.phd','yrs.service','Discipline_dummy']\n",
    "\n",
    "# coef \n",
    "coef = pd.DataFrame(np.append(lm.intercept_, lm.coef_), \n",
    "                    index_name, columns = ['coefficients'])\n",
    "# 4. evaluate the model\n",
    "print('MSE linear regression using only 3 variables: ', \n",
    "      mean_squared_error(y_test, y_pred))\n",
    "print('RMSE linear regression using only 3 variables: ', \n",
    "      math.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('R2 linear regression using only 3 variables: ', \n",
    "      r2_score(y_test, y_pred))\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's use all the variables, convert all the categorical ones and the fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let'use first pd.get_dummies\n",
    "# NB remebr we always have to drop one of the dummy,\n",
    "# to avoid multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " pd.factorize(data['rank']) is different than get dummies Encode the object as an enumerated type or categorical variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take the Original data set and let's look at it\n",
    "X.head()\n",
    "# we need to convert: rank, disicpline and sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) using get_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the X matrix that is already a dataframe since now on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_d = pd.get_dummies(data['rank'])\n",
    "discipline_d = pd.get_dummies(data['discipline'])\n",
    "sex_d = pd.get_dummies(data['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rank_d.head())\n",
    "print(discipline_d.head())\n",
    "print(sex_d.head())\n",
    "# we need to drop one dymmy for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are multiple ways to select only one column\n",
    "# we review a little bit of indexing\n",
    "# 1.\n",
    "rank_dummy = rank_d.drop('AssocProf', axis = 1)\n",
    "discipline_dummy = discipline_d.drop('A', axis = 1)\n",
    "sex_dummy = sex_d.drop('Female', axis = 1)\n",
    "\n",
    "2. \n",
    "rank_dummy2 = rank_d.iloc[:,1::]\n",
    "discipline_dummy2 = discipline_d.iloc[:,1::]\n",
    "sex_dummy2 = sex_d.iloc[:,1::]\n",
    "\n",
    "print(rank_dummy)\n",
    "print(rank_dummy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Much easier way, get_dummies has thought about everything already\n",
    "\n",
    "rank_d3 = pd.get_dummies(data['rank'], drop_first = True)\n",
    "discipline_d3 = pd.get_dummies(data['discipline'], drop_first = True)\n",
    "sex_d3 = pd.get_dummies(data['sex'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to add the dummy to our dataframe\n",
    "# we use pd.concat and the first one\n",
    "X_get_dummies = pd.concat([X, rank_d3, discipline_d3, sex_d3],\n",
    "                          axis = 1)\n",
    "X_get_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to drop the categoriacal variable\n",
    "X_get_dummies = X_get_dummies.drop(['rank', 'discipline','sex'],\n",
    "                                   axis = 'columns')\n",
    "X_get_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. split the sample\n",
    "\n",
    "X_train, X_test, y_train,y_test = train_test_split(X_get_dummies, y,\n",
    "                                                  test_size = 0.2,\n",
    "                                                  random_state = 10)\n",
    "\n",
    "# 2. fit the model\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "# 3. predict the model\n",
    "y_pred = lm.predict(X_test)\n",
    "y_train_pred = lm.predict(X_train)\n",
    "\n",
    "index_name = ['intercept']\n",
    "for i in X_train.columns:\n",
    "    index_name.append(i)\n",
    "\n",
    "# coef \n",
    "coef = pd.DataFrame(np.append(lm.intercept_, lm.coef_), \n",
    "                    index_name, columns = ['coefficients'])\n",
    "\n",
    "# 4. evaluate the model\n",
    "print('MSE oos linear regression using all variables: ', \n",
    "      mean_squared_error(y_test, y_pred))\n",
    "print('RMSE oos linear regression using all variables: ', \n",
    "      math.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('R2 oos linear regression using all variables: ', \n",
    "      r2_score(y_test, y_pred))\n",
    "\n",
    "print('MSE insample linear regression using all variables: ', \n",
    "      mean_squared_error(y_train, y_train_pred))\n",
    "print('RMSE insample linear regression using all variables: ', \n",
    "      math.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "print('R2 insample linear regression using all variables: ', \n",
    "      r2_score(y_train, y_train_pred))\n",
    "\n",
    "coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) using LabelEncoder() and OneHotEncored()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "# disicipline and sex can be analized using le\n",
    "discipline_d = le.fit_transform(data['discipline'])\n",
    "sex_d = le.fit_transform(data['sex'])\n",
    "\n",
    "# rank need one hot encoder\n",
    "# 1. select unique categories\n",
    "cat = pd.unique(data['rank']).ravel()\n",
    "\n",
    "#2. define OneHotEncoders feattures, remebr to drop the first feature\n",
    "#   to avoid collinearity. we don't need to do it in labelencoder\n",
    "ohe = OneHotEncoder(sparse = False, categories = [cat])\n",
    "\n",
    "rank_d = ohe.fit_transform(data[['rank']])\n",
    "rank_d = np.asarray(rank_d[:,1::], dtype = int)   # convert into int.\n",
    "\n",
    "#  create the new dataset, we want a dataframe so we have two choices:\n",
    "# 1. crate a np.matrix and convert it into a DataFrame\n",
    "X_le_tmp = np.hstack((data.values, rank_d, discipline_d.reshape(-1,1),\n",
    "          sex_d.reshape(-1,1)))\n",
    "names_col = ['rank', 'discipline', 'yrs.since.phd', 'yrs.service', 'sex',\n",
    "            'salary', 'rank_d1', 'rank_d2', 'discipline_d', 'sex_d']\n",
    "X_le_tmp = pd.DataFrame(X_le_tmp, columns = names_col)\n",
    "\n",
    "# 2. convert dummies in dataframe and append them to the original data\n",
    "rank_d = pd.DataFrame(rank_d, columns = ['rank_d1', 'rank_d2'])\n",
    "discipline_d = pd.DataFrame(discipline_d, columns = ['disicpline_d'])\n",
    "sex_d = pd.DataFrame(sex_d, columns = ['sex_d'])\n",
    "\n",
    "X_le_tmp2 = pd.concat([data, rank_d, discipline_d, sex_d], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to drop the original comlumns\n",
    "# Let's remebr to drop also salary!!\n",
    "X_le = X_le_tmp.drop(['rank','discipline','sex', 'salary'], axis = 1)\n",
    "X_le2 = X_le_tmp2.drop(['rank','discipline','sex', 'salary'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's fit the lineat model\n",
    "\n",
    "# 1. split the sample\n",
    "X_train, X_test, y_train,y_test = train_test_split(X_le, y,\n",
    "                                                  test_size = 0.2,\n",
    "                                                  random_state = 10)\n",
    "\n",
    "# 2. fit the model\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "# 3. predict the model\n",
    "y_pred = lm.predict(X_test)\n",
    "y_trian_pred = lm.predict(X_train)\n",
    "index_name = ['intercept']\n",
    "for i in X_train.columns:\n",
    "    index_name.append(i)\n",
    "\n",
    "# coef \n",
    "coef = pd.DataFrame(np.append(lm.intercept_, lm.coef_), \n",
    "                    index_name, columns = ['coefficients'])\n",
    "\n",
    "# 4. evaluate the model\n",
    "print('MSE linear regression using all variables: ', \n",
    "      mean_squared_error(y_test, y_pred))\n",
    "print('RMSE linear regression using all variables: ', \n",
    "      math.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('R2 linear regression using only all variable: ', \n",
    "      r2_score(y_test, y_pred))\n",
    "\n",
    "print('MSE insample linear regression using all variables: ', \n",
    "      mean_squared_error(y_train, y_train_pred))\n",
    "print('RMSE insample linear regression using all variables: ', \n",
    "      math.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "print('R2 insample linear regression using all variables: ', \n",
    "      r2_score(y_train, y_train_pred))\n",
    "\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
